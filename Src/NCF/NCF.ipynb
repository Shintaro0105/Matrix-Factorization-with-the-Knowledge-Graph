{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b22db89-156b-4342-8ece-428b44c61c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.10 (default, Sep 28 2021, 16:10:42) \n",
      "[GCC 9.3.0]\n",
      "Pandas version: 1.5.1\n",
      "Tensorflow version: 2.7.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cornac\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.models.ncf.ncf_singlenode import NCF\n",
    "from recommenders.models.ncf.dataset import Dataset as NCFDataset\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_chrono_split\n",
    "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, \n",
    "                                                     recall_at_k, get_top_k_items)\n",
    "from recommenders.utils.constants import SEED as DEFAULT_SEED\n",
    "\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c14012c-66d7-4a17-ad6e-7c615c5b5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "SEED = DEFAULT_SEED  # Set None for non-deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e675ba1a-8e60-4ab3-b90d-672ff809d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('../data/um.dat', 'r') as infile:\n",
    "    for line in infile.readlines():\n",
    "        user, item, rating = line.strip().split('\\t')\n",
    "        data.append([int(user), int(item), rating])\n",
    "        \n",
    "df = pd.DataFrame(data=data, columns=[\"userID\", \"itemID\", \"rating\"])\n",
    "data = []\n",
    "with open('../data/um_0.8.train', 'r') as infile:\n",
    "    for line in infile.readlines():\n",
    "        user, item, rating = line.strip().split('\\t')\n",
    "        data.append([int(user), int(item), rating])\n",
    "        \n",
    "train = pd.DataFrame(data=data, columns=[\"userID\", \"itemID\", \"rating\"])\n",
    "data = []\n",
    "with open('../data/um_0.8.test', 'r') as infile:\n",
    "    for line in infile.readlines():\n",
    "        user, item, rating = line.strip().split('\\t')\n",
    "        data.append([int(user), int(item), rating])\n",
    "        \n",
    "test = pd.DataFrame(data=data, columns=[\"userID\", \"itemID\", \"rating\"])\n",
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e96e4b7-362f-42d3-8d91-7e36c287f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(\"userID\")\n",
    "test = test.sort_values(\"userID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95aced37-897b-4300-bed5-369599923de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[test[\"userID\"].isin(train[\"userID\"].unique())]\n",
    "test = test[test[\"itemID\"].isin(train[\"itemID\"].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9860e326-db76-46fe-abce-a755743fa98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_one_out_test = test.groupby(\"userID\").last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "144540c6-ca24-4d64-a317-b590730fa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../data/train.csv\"\n",
    "test_file = \"../data/test.csv\"\n",
    "leave_one_out_test_file = \"../data/leave_one_out_test.csv\"\n",
    "train.to_csv(train_file, index=False)\n",
    "test.to_csv(test_file, index=False)\n",
    "leave_one_out_test.to_csv(leave_one_out_test_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00a5f4c6-25c5-4e03-9db2-259aa586dad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.models.ncf.dataset:Indexing ../data/train.csv ...\n",
      "INFO:recommenders.models.ncf.dataset:Indexing ../data/leave_one_out_test.csv ...\n",
      "INFO:recommenders.models.ncf.dataset:Creating full leave-one-out test file ../data/leave_one_out_test_full.csv ...\n",
      "100%|██████████████████████████████████████| 2818/2818 [00:07<00:00, 402.05it/s]\n",
      "INFO:recommenders.models.ncf.dataset:Indexing ../data/leave_one_out_test_full.csv ...\n"
     ]
    }
   ],
   "source": [
    "data = NCFDataset(train_file=train_file, test_file=leave_one_out_test_file, seed=SEED, overwrite_test_file_full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca0a25b7-8d84-4dde-894e-d940b5fe86fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/echigo/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model = NCF (\n",
    "    n_users=data.n_users, \n",
    "    n_items=data.n_items,\n",
    "    model_type=\"NeuMF\",\n",
    "    n_factors=4,\n",
    "    layer_sizes=[16,8,4],\n",
    "    n_epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=10,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53b34e94-df8d-4f80-a021-b601708f515c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [22.58s]: train_loss = 0.256993 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 20 [25.39s]: train_loss = 0.243091 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 30 [22.44s]: train_loss = 0.236316 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 40 [20.71s]: train_loss = 0.232144 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 50 [23.42s]: train_loss = 0.229129 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 60 [21.77s]: train_loss = 0.227550 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 70 [20.50s]: train_loss = 0.225747 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 80 [21.17s]: train_loss = 0.224581 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 90 [24.87s]: train_loss = 0.223091 \n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 100 [22.55s]: train_loss = 0.223013 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2241.513431094587 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model.fit(data)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ceac669-0317-4a10-a667-ba072adce291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2111</td>\n",
       "      <td>0.488377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7241</td>\n",
       "      <td>0.926073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>386</td>\n",
       "      <td>0.635497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4045</td>\n",
       "      <td>0.812740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>9055</td>\n",
       "      <td>0.932129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction\n",
       "0       1    2111    0.488377\n",
       "1       1    7241    0.926073\n",
       "2       1     386    0.635497\n",
       "3       2    4045    0.812740\n",
       "4       2    9055    0.932129"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID)]\n",
    "               for (_, row) in test.iterrows()]\n",
    "\n",
    "\n",
    "predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75ee78f3-41a6-417b-84f7-773a109a032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 103.4089816249907 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "\n",
    "    users, items, preds = [], [], []\n",
    "    item = list(train.itemID.unique())\n",
    "    for user in train.userID.unique():\n",
    "        user = [user] * len(item) \n",
    "        users.extend(user)\n",
    "        items.extend(item)\n",
    "        preds.extend(list(model.predict(user, item, is_list=True)))\n",
    "\n",
    "    all_predictions = pd.DataFrame(data={\"userID\": users, \"itemID\":items, \"prediction\":preds})\n",
    "\n",
    "    merged = pd.merge(train, all_predictions, on=[\"userID\", \"itemID\"], how=\"outer\")\n",
    "    all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d287f1cb-8456-4c7f-a8e9-e38c2a4a6b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t0.034902\n",
      "NDCG:\t0.140789\n",
      "Precision@K:\t0.115295\n",
      "Recall@K:\t0.076867\n"
     ]
    }
   ],
   "source": [
    "TOP_K = 10\n",
    "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0c59e14-e6a9-4b36-8e7e-05c397c01357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t0.043182\n",
      "NDCG:\t0.143988\n",
      "Precision@K:\t0.098776\n",
      "Recall@K:\t0.129419\n"
     ]
    }
   ],
   "source": [
    "TOP_K = 20\n",
    "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e856a-455d-415a-90bf-b87f5a5c3c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
